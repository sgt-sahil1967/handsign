<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Hand Sign Recognition</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="container">
        <nav class="navbar">
            <a href="/dashboard" class="navbar-brand">ü§≤ Hand Sign Recognition</a>
            <ul class="navbar-nav">
                <li><a href="/dashboard">Dashboard</a></li>
                <li><a href="/detect">Detection</a></li>
                <li><a href="/how-it-works">How It Works</a></li>
                <li><a href="/about">About</a></li>
                <li><a href="/help">Help</a></li>
            </ul>
        </nav>

        <div class="info-page">
            <h1>About Hand Sign Recognition</h1>
            
            <p>
                Hand Sign Recognition is an advanced web application that uses machine learning to recognize 
                and classify hand gestures in real-time. Built with cutting-edge computer vision and deep learning 
                technologies, this application can identify various hand signs including ASL letters and common gestures.
            </p>

            <h2>Features</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h3>üéØ Real-time Detection</h3>
                    <p>Process webcam feed in real-time with instant predictions and confidence scores</p>
                </div>
                <div class="feature-card">
                    <h3>ü§ñ AI-Powered</h3>
                    <p>Uses TensorFlow Lite models trained on hand landmark data for accurate recognition</p>
                </div>
                <div class="feature-card">
                    <h3>üìä High Accuracy</h3>
                    <p>Achieves 92% accuracy in recognizing 8 different hand signs and gestures</p>
                </div>
                <div class="feature-card">
                    <h3>üåê Web-Based</h3>
                    <p>Runs entirely in your browser - no installation required, works on any device</p>
                </div>
                <div class="feature-card">
                    <h3>‚ö° Fast Processing</h3>
                    <p>Optimized inference pipeline processes frames every 500ms for smooth experience</p>
                </div>
                <div class="feature-card">
                    <h3>üîí Privacy-Focused</h3>
                    <p>All processing happens locally - your video never leaves your device</p>
                </div>
            </div>

            <h2>Supported Hand Signs</h2>
            <p>The application can recognize the following hand signs:</p>
            <ul>
                <li><strong>Open</strong> - Open hand gesture</li>
                <li><strong>Close</strong> - Closed fist</li>
                <li><strong>Pointer</strong> - Pointing gesture</li>
                <li><strong>OK</strong> - OK sign</li>
                <li><strong>ASL A</strong> - American Sign Language letter A</li>
                <li><strong>ASL B</strong> - American Sign Language letter B</li>
                <li><strong>ASL C</strong> - American Sign Language letter C</li>
                <li><strong>ASL D</strong> - American Sign Language letter D</li>
            </ul>

            <h2>Technology Stack</h2>
            <div class="tech-stack">
                <span class="tech-badge">Python 3.11</span>
                <span class="tech-badge">Flask</span>
                <span class="tech-badge">TensorFlow Lite</span>
                <span class="tech-badge">MediaPipe</span>
                <span class="tech-badge">OpenCV</span>
                <span class="tech-badge">JavaScript</span>
                <span class="tech-badge">HTML5</span>
                <span class="tech-badge">CSS3</span>
            </div>

            <h2>How It Works</h2>
            <p>
                The application uses a two-stage machine learning pipeline:
            </p>
            <ol>
                <li><strong>Hand Detection & Landmark Extraction</strong>: MediaPipe detects hands in the video frame and extracts 21 key landmark points</li>
                <li><strong>Gesture Classification</strong>: TensorFlow Lite models classify the hand landmarks into specific gestures</li>
                <li><strong>Finger Gesture Recognition</strong>: Additional model tracks finger movements for dynamic gestures</li>
            </ol>

            <h2>Performance</h2>
            <ul>
                <li><strong>Model Accuracy</strong>: 92% on test dataset</li>
                <li><strong>Processing Speed</strong>: ~2 FPS (frames per second) for predictions</li>
                <li><strong>Latency</strong>: < 500ms per prediction</li>
                <li><strong>Supported Devices</strong>: Any device with a webcam and modern browser</li>
            </ul>

            <div style="text-align: center; margin-top: 2rem;">
                <a href="/detect" class="btn-primary">Try It Now</a>
                <a href="/how-it-works" class="btn-link" style="margin-left: 1rem;">Learn More</a>
            </div>
        </div>
    </div>
</body>
</html>



